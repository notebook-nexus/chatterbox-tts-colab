{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Chatterbox TTS Google Colab Script\n",
        "==================================\n",
        "\n",
        "A comprehensive script for text-to-speech generation and voice cloning using\n",
        "Chatterbox TTS in Google Colab environment.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- Author: ukr\n",
        "- License: MIT\n",
        "- Repository: https://github.com/notebook-nexus/chatterbox-tts-colab\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Features:\n",
        "- Automatic dependency installation with fallbacks\n",
        "- Voice cloning from audio samples\n",
        "- Long text processing with chunking\n",
        "- Google Drive integration\n",
        "- Robust error handling\n",
        "- GPU/CPU automatic detection\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "36DKyrQCWD1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Installation and Dependencies\n",
        "\n",
        "---\n",
        "Run this cell first, then WAIT for kernel restart"
      ],
      "metadata": {
        "id": "709tUDEL_IZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def run_command(command, description=\"\"):\n",
        "    \"\"\"Run a command and handle errors gracefully\"\"\"\n",
        "    print(f\"Running: {description if description else command}\")\n",
        "    try:\n",
        "        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "        if result.returncode != 0:\n",
        "            print(f\"Warning: {description} failed with return code {result.returncode}\")\n",
        "            print(f\"stderr: {result.stderr}\")\n",
        "            print(f\"stdout: {result.stdout}\")\n",
        "            return False\n",
        "        else:\n",
        "            print(f\"Success: {description}\")\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error running command: {e}\")\n",
        "        return False\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Update pip first\n",
        "run_command(\"pip install --upgrade pip\", \"Upgrading pip\")\n",
        "\n",
        "# Install PyTorch (CPU version for compatibility)\n",
        "print(\"Installing PyTorch...\")\n",
        "run_command(\n",
        "    \"pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu --force-reinstall\",\n",
        "    \"Installing PyTorch (CPU version for stability)\"\n",
        ")\n",
        "\n",
        "# Install git-lfs for handling large files\n",
        "run_command(\"apt update && apt install -y git-lfs\", \"Installing git-lfs\")\n",
        "\n",
        "# Install chatterbox-tts\n",
        "print(\"Installing Chatterbox TTS...\")\n",
        "chatterbox_success = run_command(\n",
        "    \"pip install chatterbox-tts --no-cache-dir --force-reinstall\",\n",
        "    \"Installing Chatterbox TTS\"\n",
        ")\n",
        "\n",
        "if not chatterbox_success:\n",
        "    print(\"PyPI installation failed. Trying GitHub installation...\")\n",
        "    run_command(\n",
        "        \"git clone https://github.com/resemble-ai/chatterbox.git /tmp/chatterbox\",\n",
        "        \"Cloning Chatterbox repository\"\n",
        "    )\n",
        "    run_command(\n",
        "        \"cd /tmp/chatterbox && pip install -e .\",\n",
        "        \"Installing Chatterbox from source\"\n",
        "    )\n",
        "\n",
        "# Fix for protobuf error\n",
        "print(\"Fixing protobuf version conflict...\")\n",
        "run_command(\"pip uninstall -y protobuf\", \"Uninstalling existing protobuf\")\n",
        "run_command(\"pip install protobuf==3.20.3\", \"Installing compatible protobuf version\")\n",
        "\n",
        "\n",
        "print(\"\\nüîÑ Dependencies installed. Restarting kernel...\")\n",
        "print(\"‚ö†Ô∏è  WAIT for kernel restart, then run the next cell!\")\n",
        "get_ipython().kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "XbWrDWhV_dPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Verify Installation\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Run this cell after kernel restart"
      ],
      "metadata": {
        "id": "U6ww_yvD_emo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify installation\n",
        "try:\n",
        "    import torch\n",
        "    import torchaudio\n",
        "    from chatterbox.tts import ChatterboxTTS\n",
        "    print(\"‚úÖ All imports successful!\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"CUDA version: {torch.version.cuda}\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"Please run the installation cell again\")"
      ],
      "metadata": {
        "id": "Rs27aufP_vzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Google Drive Setup\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Run this cell to set up Google Drive"
      ],
      "metadata": {
        "id": "axx855TH_x18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "def setup_drive():\n",
        "    \"\"\"Setup Google Drive mount and create necessary directories\"\"\"\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        drive_path = '/content/drive/MyDrive/Chatterbox'\n",
        "        os.makedirs(drive_path, exist_ok=True)\n",
        "        print(f\"‚úÖ Drive setup complete: {drive_path}\")\n",
        "        return drive_path\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Drive setup failed: {e}\")\n",
        "        return None\n",
        "\n",
        "DRIVE_PATH = setup_drive()"
      ],
      "metadata": {
        "id": "FXihy93x_z-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Model Loading with Advanced Configuration\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Load the Chatterbox model"
      ],
      "metadata": {
        "id": "FK8ezC7R_3dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from chatterbox.tts import ChatterboxTTS\n",
        "\n",
        "def load_model(max_retries=3):\n",
        "    \"\"\"Load the Chatterbox model with retry logic\"\"\"\n",
        "    try:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        print(f\"Loading model on device: {device}\")\n",
        "\n",
        "        model = ChatterboxTTS.from_pretrained(device=device)\n",
        "        print(\"‚úÖ Model loaded successfully\")\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Model loading failed: {e}\")\n",
        "        print(\"Trying CPU fallback...\")\n",
        "\n",
        "        try:\n",
        "            model = ChatterboxTTS.from_pretrained(device=\"cpu\")\n",
        "            print(\"‚úÖ Model loaded successfully on CPU\")\n",
        "            return model\n",
        "        except Exception as e2:\n",
        "            print(f\"‚ùå CPU fallback also failed: {e2}\")\n",
        "            raise e2\n",
        "\n",
        "# Load the model\n",
        "model = load_model()"
      ],
      "metadata": {
        "id": "_1rXTk7e_3E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Advanced Controls Configuration\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Configure advanced parameters for voice generation"
      ],
      "metadata": {
        "id": "MLkCkm3U_60U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üéõÔ∏è ADVANCED CONTROLS - Adjust these parameters for different effects\n",
        "\n",
        "class ChatterboxConfig:\n",
        "    \"\"\"Advanced configuration for Chatterbox TTS\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # üé≠ EXAGGERATION CONTROL (0.0 - 2.0)\n",
        "        # Controls emotional intensity and expressiveness\n",
        "        # 0.5 = Neutral (default)\n",
        "        # 0.3-0.4 = Subtle, calm\n",
        "        # 0.6-0.8 = More expressive\n",
        "        # 1.0+ = Very dramatic\n",
        "        self.exaggeration = 0.5\n",
        "\n",
        "        # ‚ö° CFG WEIGHT (0.1 - 1.0)\n",
        "        # Controls adherence to reference audio style\n",
        "        # 0.3 = Faster pacing, less strict adherence\n",
        "        # 0.5 = Balanced (default)\n",
        "        # 0.7+ = Slower, more faithful to reference\n",
        "        self.cfg_weight = 0.5\n",
        "\n",
        "        # üìè TEXT CHUNKING\n",
        "        # Maximum words per chunk (recommended: 30-100)\n",
        "        self.max_chunk_words = 50\n",
        "\n",
        "        # üé§ VOICE CLONING SETTINGS\n",
        "        # Minimum recommended audio length: 10 seconds\n",
        "        # Optimal format: WAV, 16-22kHz sample rate\n",
        "        self.voice_sample_path = None\n",
        "\n",
        "    def get_preset(self, preset_name):\n",
        "        \"\"\"Get predefined parameter presets\"\"\"\n",
        "        presets = {\n",
        "            \"neutral\": {\"exaggeration\": 0.5, \"cfg_weight\": 0.5},\n",
        "            \"calm\": {\"exaggeration\": 0.3, \"cfg_weight\": 0.6},\n",
        "            \"expressive\": {\"exaggeration\": 0.7, \"cfg_weight\": 0.4},\n",
        "            \"dramatic\": {\"exaggeration\": 1.0, \"cfg_weight\": 0.3},\n",
        "            \"storytelling\": {\"exaggeration\": 0.8, \"cfg_weight\": 0.4},\n",
        "            \"audiobook\": {\"exaggeration\": 0.4, \"cfg_weight\": 0.6},\n",
        "            \"fast_speaker\": {\"exaggeration\": 0.6, \"cfg_weight\": 0.3},\n",
        "        }\n",
        "        return presets.get(preset_name, presets[\"neutral\"])\n",
        "\n",
        "# Initialize configuration\n",
        "config = ChatterboxConfig()\n",
        "\n",
        "# üéöÔ∏è CHOOSE YOUR PRESET OR CUSTOMIZE\n",
        "# Uncomment one of these lines:\n",
        "\n",
        "# config.__dict__.update(config.get_preset(\"neutral\"))      # Balanced, natural\n",
        "# config.__dict__.update(config.get_preset(\"expressive\"))   # More emotional\n",
        "# config.__dict__.update(config.get_preset(\"storytelling\")) # Great for narratives\n",
        "# config.__dict__.update(config.get_preset(\"audiobook\"))    # Clear, consistent\n",
        "# config.__dict__.update(config.get_preset(\"dramatic\"))     # Very expressive\n",
        "\n",
        "# OR customize manually:\n",
        "config.exaggeration = 0.6  # Adjust 0.0-2.0\n",
        "config.cfg_weight = 0.4     # Adjust 0.1-1.0\n",
        "\n",
        "print(f\"üéõÔ∏è Current settings:\")\n",
        "print(f\"   Exaggeration: {config.exaggeration}\")\n",
        "print(f\"   CFG Weight: {config.cfg_weight}\")\n",
        "print(f\"   Chunk size: {config.max_chunk_words} words\")"
      ],
      "metadata": {
        "id": "5YGJlUtQAC68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Voice Sample Setup (Optional)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Set up voice cloning with your own audio"
      ],
      "metadata": {
        "id": "dbp-F4rmAExb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üé§ VOICE CLONING SETUP\n",
        "\n",
        "def setup_voice_cloning():\n",
        "    \"\"\"Setup voice cloning with instructions\"\"\"\n",
        "    print(\"üé§ VOICE CLONING SETUP\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"For best results, your voice sample should:\")\n",
        "    print(\"‚Ä¢ Be at least 10 seconds long (ideally 15-30 seconds)\")\n",
        "    print(\"‚Ä¢ Be in WAV format\")\n",
        "    print(\"‚Ä¢ Have clear, consistent audio quality\")\n",
        "    print(\"‚Ä¢ Contain natural speech (avoid reading lists/monotone)\")\n",
        "    print(\"‚Ä¢ Be recorded in a quiet environment\")\n",
        "    print(\"‚Ä¢ Match the speaking style you want to generate\")\n",
        "    print()\n",
        "\n",
        "    if DRIVE_PATH:\n",
        "        sample_path = f\"{DRIVE_PATH}/voice_sample.wav\"\n",
        "        print(f\"üìÅ Upload your voice sample to: {sample_path}\")\n",
        "        print(\"   Or use Google Colab's file upload feature\")\n",
        "\n",
        "        # Check if sample exists\n",
        "        if os.path.exists(sample_path):\n",
        "            print(f\"‚úÖ Voice sample found: {sample_path}\")\n",
        "            config.voice_sample_path = sample_path\n",
        "            return sample_path\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  No voice sample found at {sample_path}\")\n",
        "            print(\"   Voice cloning will be disabled\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"‚ùå Google Drive not mounted - voice cloning disabled\")\n",
        "        return None\n",
        "\n",
        "# Setup voice cloning\n",
        "voice_sample = setup_voice_cloning()\n",
        "\n",
        "# Alternative: Upload file directly in Colab\n",
        "print(\"\\nüì§ Alternative: Upload file directly\")\n",
        "print(\"Run this code in a separate cell if you want to upload directly:\")\n",
        "print(\"\"\"\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    config.voice_sample_path = filename\n",
        "    print(f\"‚úÖ Voice sample uploaded: {filename}\")\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "B2CmeqwfAICk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7: Text Processing Functions\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Helper functions for text processing"
      ],
      "metadata": {
        "id": "ME4HsABDAKFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_into_chunks(text, max_words=100):\n",
        "    \"\"\"Split text into manageable chunks for processing\"\"\"\n",
        "    # Clean and split text\n",
        "    sentences = text.strip().replace('\\n', ' ').split('.')\n",
        "    sentences = [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_word_count = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_words = sentence.split()\n",
        "\n",
        "        # If adding this sentence exceeds max_words, start new chunk\n",
        "        if current_word_count + len(sentence_words) > max_words and current_chunk:\n",
        "            chunks.append(current_chunk.strip() + \".\")\n",
        "            current_chunk = sentence\n",
        "            current_word_count = len(sentence_words)\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                current_chunk += \". \" + sentence\n",
        "            else:\n",
        "                current_chunk = sentence\n",
        "            current_word_count += len(sentence_words)\n",
        "\n",
        "    # Add the last chunk\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip() + \".\")\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def estimate_processing_time(text, words_per_minute=150):\n",
        "    \"\"\"Estimate processing time based on text length\"\"\"\n",
        "    word_count = len(text.split())\n",
        "    estimated_minutes = word_count / words_per_minute\n",
        "    return word_count, estimated_minutes\n",
        "\n",
        "# Test the functions\n",
        "sample_text = \"\"\"\n",
        "This is a test of the enhanced Chatterbox TTS system.\n",
        "The system now includes advanced controls for voice quality and expression.\n",
        "You can adjust parameters like exaggeration and CFG weight for different effects.\n",
        "\"\"\"\n",
        "\n",
        "chunks = split_into_chunks(sample_text, config.max_chunk_words)\n",
        "word_count, time_est = estimate_processing_time(sample_text)\n",
        "\n",
        "print(f\"üìä Text Analysis:\")\n",
        "print(f\"   Total words: {word_count}\")\n",
        "print(f\"   Estimated time: {time_est:.1f} minutes\")\n",
        "print(f\"   Number of chunks: {len(chunks)}\")\n",
        "print(f\"   Chunk preview: '{chunks[0][:50]}...'\")"
      ],
      "metadata": {
        "id": "vhwCu3N0APSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8: Main TTS Generation\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Generate speech with your configured settings"
      ],
      "metadata": {
        "id": "MpPITEjcAQby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_speech(text, config, model, output_filename=\"generated_speech.wav\"):\n",
        "    \"\"\"Generate speech with advanced controls\"\"\"\n",
        "\n",
        "    print(\"üéôÔ∏è STARTING SPEECH GENERATION\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Analyze text\n",
        "    chunks = split_into_chunks(text, config.max_chunk_words)\n",
        "    word_count, time_est = estimate_processing_time(text)\n",
        "\n",
        "    print(f\"üìù Text: {word_count} words, {len(chunks)} chunks\")\n",
        "    print(f\"‚è±Ô∏è  Estimated time: {time_est:.1f} minutes\")\n",
        "    print(f\"üéõÔ∏è Settings: exaggeration={config.exaggeration}, cfg_weight={config.cfg_weight}\")\n",
        "\n",
        "    if config.voice_sample_path and os.path.exists(config.voice_sample_path):\n",
        "        print(f\"üé§ Using voice cloning: {config.voice_sample_path}\")\n",
        "    else:\n",
        "        print(\"ü§ñ Using default voice (no cloning)\")\n",
        "\n",
        "    print(\"\\nüîÑ Processing chunks...\")\n",
        "\n",
        "    wav_tensors = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"Processing chunk {i+1}/{len(chunks)}: '{chunk[:50]}...'\")\n",
        "\n",
        "        try:\n",
        "            # Generate parameters\n",
        "            gen_params = {\n",
        "                \"text\": chunk,\n",
        "                \"exaggeration\": config.exaggeration,\n",
        "                \"cfg_weight\": config.cfg_weight\n",
        "            }\n",
        "\n",
        "            # Add voice cloning if available\n",
        "            if config.voice_sample_path and os.path.exists(config.voice_sample_path):\n",
        "                gen_params[\"audio_prompt_path\"] = config.voice_sample_path\n",
        "\n",
        "            # Generate audio\n",
        "            wav = model.generate(**gen_params)\n",
        "            wav_tensors.append(wav)\n",
        "\n",
        "            # Clear GPU memory if available\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in chunk {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Combine and save audio\n",
        "    if wav_tensors:\n",
        "        print(f\"\\nüíæ Saving {len(wav_tensors)} audio chunks...\")\n",
        "        full_audio = torch.cat(wav_tensors, dim=1)\n",
        "\n",
        "        if DRIVE_PATH:\n",
        "            output_path = f\"{DRIVE_PATH}/{output_filename}\"\n",
        "            torchaudio.save(output_path, full_audio, model.sr)\n",
        "            print(f\"‚úÖ Audio saved to: {output_path}\")\n",
        "\n",
        "            # Also save to local for immediate playback\n",
        "            local_path = f\"/content/{output_filename}\"\n",
        "            torchaudio.save(local_path, full_audio, model.sr)\n",
        "            print(f\"üì± Local copy: {local_path}\")\n",
        "\n",
        "            return output_path, local_path\n",
        "        else:\n",
        "            local_path = f\"/content/{output_filename}\"\n",
        "            torchaudio.save(local_path, full_audio, model.sr)\n",
        "            print(f\"‚úÖ Audio saved to: {local_path}\")\n",
        "            return local_path, local_path\n",
        "    else:\n",
        "        print(\"‚ùå No audio was generated\")\n",
        "        return None, None\n",
        "\n",
        "# üìù YOUR TEXT HERE - Edit this!\n",
        "your_text = \"\"\"\n",
        "Welcome to the enhanced Chatterbox TTS system!\n",
        "This demonstration showcases the advanced voice synthesis capabilities with customizable parameters.\n",
        "You can adjust the exaggeration level to make the voice more or less expressive.\n",
        "The CFG weight parameter controls how closely the system follows the reference audio style.\n",
        "This technology opens up exciting possibilities for content creation, accessibility, and entertainment.\n",
        "\"\"\"\n",
        "\n",
        "# Generate speech\n",
        "output_path, local_path = generate_speech(your_text, config, model)"
      ],
      "metadata": {
        "id": "s2CGLnnyASs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9: Audio Playback and Analysis\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Play and analyze the generated audio"
      ],
      "metadata": {
        "id": "pc41oNJAAVgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def play_and_analyze_audio(audio_path):\n",
        "    \"\"\"Play audio and show waveform analysis\"\"\"\n",
        "    if not audio_path or not os.path.exists(audio_path):\n",
        "        print(\"‚ùå No audio file to play\")\n",
        "        return\n",
        "\n",
        "    print(f\"üîä Playing audio: {audio_path}\")\n",
        "\n",
        "    # Play audio\n",
        "    ipd.display(ipd.Audio(audio_path))\n",
        "\n",
        "    # Load and analyze waveform\n",
        "    try:\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        duration = waveform.shape[1] / sample_rate\n",
        "\n",
        "        print(f\"üìä Audio Analysis:\")\n",
        "        print(f\"   Duration: {duration:.2f} seconds\")\n",
        "        print(f\"   Sample Rate: {sample_rate} Hz\")\n",
        "        print(f\"   Channels: {waveform.shape[0]}\")\n",
        "\n",
        "        # Plot waveform\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.plot(waveform[0].numpy())\n",
        "        plt.title(\"Generated Audio Waveform\")\n",
        "        plt.xlabel(\"Sample\")\n",
        "        plt.ylabel(\"Amplitude\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error analyzing audio: {e}\")\n",
        "\n",
        "# Play the generated audio\n",
        "if local_path:\n",
        "    play_and_analyze_audio(local_path)"
      ],
      "metadata": {
        "id": "0s1Zf_dwAWkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 10: Parameter Experimentation\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Test different parameter combinations"
      ],
      "metadata": {
        "id": "H_J9AVbYAbgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_with_parameters(text, model):\n",
        "    \"\"\"Generate multiple versions with different parameter combinations\"\"\"\n",
        "\n",
        "    experiments = [\n",
        "        {\"name\": \"Neutral\", \"exaggeration\": 0.5, \"cfg_weight\": 0.5},\n",
        "        {\"name\": \"Expressive\", \"exaggeration\": 0.8, \"cfg_weight\": 0.4},\n",
        "        {\"name\": \"Calm\", \"exaggeration\": 0.3, \"cfg_weight\": 0.6},\n",
        "        {\"name\": \"Dramatic\", \"exaggeration\": 1.0, \"cfg_weight\": 0.3},\n",
        "    ]\n",
        "\n",
        "    short_text = \"Hello! This is a test of different voice parameters.\"\n",
        "\n",
        "    print(\"üß™ PARAMETER EXPERIMENTS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for exp in experiments:\n",
        "        print(f\"\\nüé≠ Testing: {exp['name']}\")\n",
        "        print(f\"   Exaggeration: {exp['exaggeration']}, CFG Weight: {exp['cfg_weight']}\")\n",
        "\n",
        "        try:\n",
        "            gen_params = {\n",
        "                \"text\": short_text,\n",
        "                \"exaggeration\": exp['exaggeration'],\n",
        "                \"cfg_weight\": exp['cfg_weight']\n",
        "            }\n",
        "\n",
        "            if config.voice_sample_path and os.path.exists(config.voice_sample_path):\n",
        "                gen_params[\"audio_prompt_path\"] = config.voice_sample_path\n",
        "\n",
        "            wav = model.generate(**gen_params)\n",
        "\n",
        "            # Save and play\n",
        "            filename = f\"experiment_{exp['name'].lower()}.wav\"\n",
        "            filepath = f\"/content/{filename}\"\n",
        "            torchaudio.save(filepath, wav, model.sr)\n",
        "\n",
        "            print(f\"   ‚úÖ Generated: {filename}\")\n",
        "            print(f\"   üîä Playing...\")\n",
        "            ipd.display(ipd.Audio(filepath))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error: {e}\")\n",
        "\n",
        "# Run experiments with a short text\n",
        "experiment_with_parameters(\"Hello! This is a test of different voice parameters.\", model)"
      ],
      "metadata": {
        "id": "VsILBO_BAd-L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
